<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Campaign for AI Regulation | Control AI</title>
    <link rel="icon" type="image/x-icon" href="/assets/images/favicon.ico">
    <link rel="stylesheet" href="/assets/css/styles.css">
</head>
<body>
    <nav class="nav">
        <div class="nav-wrapper">
            <a href="https://controlai.com/">
                <img src="/assets/images/logo.png" alt="Control AI" class="nav-logo">
            </a>
            <a href="/index.html" class="nav-campaign">CAMPAIGN</a>
            <div class="nav-links">
                <a href="/statement/statement.html" class="nav-link">STATEMENT</a>
                <a href="/policies/policies.html" class="nav-link">OUR POLICIES</a>
                <a href="/polls/polls.html" class="nav-link">OUR POLLS</a>
                <a href="/join.html" class="nav-button">JOIN THE CAMPAIGN</a>
            </div>
        </div>
    </nav>

    <div class="container">
        <header>
            <h1>DEC 2024 - PRESENT</h1>
            <h2>Campaign for AI Regulation</h2>
        </header>

        <div class="section background">
            <h3>Background</h3>
            <p>The UK government has committed to transforming voluntary AI safety commitments from the Bletchley Park and Seoul Summits into binding regulation. This includes establishing an independent AI regulator with real powers to ensure safe AI development.</p>
            <p>There is a simple truth - humanity's extinction is possible. Recent history has shown us we can create artificial intelligence that can rival humanity. We do not know how to control AI vastly more powerful than us. Should attempts to build superintelligence succeed, this would risk our extinction as a species.</p>
        </div>

        <div class="section achievements">
            <h3>Achievements</h3>
            <ul>
                <li>Building cross-party coalition for comprehensive AI regulation</li>
                <li>Development of detailed regulatory framework proposals</li>
                <li>Engagement with leading tech companies and research institutions</li>
                <li>Drafting of model legislation for AI oversight</li>
            </ul>
        </div>

        <div class="section media">
            <h3>Media Coverage</h3>
            <div class="media-grid">
                <div class="media-item">
                    <h4>THE GUARDIAN</h4>
                    <p>UK Government Pledges New Powers for AI Regulator</p>
                    <a href="#" class="go-to-source">GO TO SOURCE</a>
                </div>
                <div class="media-item">
                    <h4>FINANCIAL TIMES</h4>
                    <p>Tech Leaders Back Stronger AI Oversight</p>
                    <a href="#" class="go-to-source">GO TO SOURCE</a>
                </div>
                <div class="media-item">
                    <h4>BBC NEWS</h4>
                    <p>MPs Call for Independent AI Watchdog</p>
                    <a href="#" class="go-to-source">GO TO SOURCE</a>
                </div>
            </div>
        </div>

        <div class="section recent-campaigns">
            <h3>Recent Campaigns</h3>
            <div class="campaign-list">
                <div class="campaign-item">
                    <h4>Campaign against deepfakes</h4>
                    <p>Deepfakes are a growing threat to society, and governments must act.</p>
                    <a href="#" class="link">READ MORE</a>
                </div>
                <div class="campaign-item">
                    <h4>Campaign against exemptions for Foundation Models</h4>
                    <p>Foundation models are general-purpose AI models that have capabilities and powers which their developers cannot predict.</p>
                    <a href="#" class="link">READ MORE</a>
                </div>
            </div>
        </div>
    </div>
</body>
</html>